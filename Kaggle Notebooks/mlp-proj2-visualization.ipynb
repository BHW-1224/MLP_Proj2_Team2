{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nimport joblib\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\ntrain = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\n\ndef encode_label(row):\n    if row[\"winner_model_a\"] == 1:\n        return 0\n    elif row[\"winner_model_b\"] == 1:\n        return 1\n    else:\n        return 2\n\ndef style_counts(text):\n    ex = text.count(\"!\")\n    qm = text.count(\"?\")\n    co = text.count(\",\")\n    return ex, qm, co\n\ndef lexical_diversity(text):\n    words = [w.lower() for w in text.split() if w.isalpha()]\n    return len(set(words)) / (len(words) + 1e-6)\n\ntrain[\"win_label\"] = train.apply(encode_label, axis=1)\n\na_win_rate = (train[\"win_label\"] == 0).mean()\nb_win_rate = (train[\"win_label\"] == 1).mean()\ntie_rate  = (train[\"win_label\"] == 2).mean()\n\nrate_df = pd.DataFrame({\n    \"Outcome\": [\"A_win\", \"B_win\", \"Tie\"],\n    \"Rate\": [a_win_rate, b_win_rate, tie_rate]\n})\n\nsns.set(style=\"whitegrid\", font_scale=1.1)\nplt.figure(figsize=(5,4))\nsns.barplot(x=\"Outcome\", y=\"Rate\", data=rate_df,\n            palette=[\"#4A90E2\", \"#E94E77\", \"#F5C518\"])\nplt.title(\"Position Bias â€” Overall Outcome Distribution\", fontsize=13)\nplt.ylabel(\"Proportion\")\nplt.ylim(0,1)\nfor container in plt.gca().containers:\n    plt.bar_label(container, fmt=\"%.2f\", fontsize=11)\nplt.tight_layout()\nplt.show()\n\n# -----------------------------------------------------------------#\n\ntrain[\"a_len\"] = train[\"response_a\"].astype(str).apply(len)\ntrain[\"b_len\"] = train[\"response_b\"].astype(str).apply(len)\ntrain[\"a_word_cnt\"] = train[\"response_a\"].astype(str).apply(lambda x: len(x.split()))\ntrain[\"b_word_cnt\"] = train[\"response_b\"].astype(str).apply(lambda x: len(x.split()))\ntrain[\"a_sent_cnt\"] = train[\"response_a\"].astype(str).apply(lambda x: x.count(\".\")+x.count(\"!\")+x.count(\"?\"))\ntrain[\"b_sent_cnt\"] = train[\"response_b\"].astype(str).apply(lambda x: x.count(\".\")+x.count(\"!\")+x.count(\"?\"))\n\ntrain[\"diff_char_len\"] = train[\"a_len\"] - train[\"b_len\"]\ntrain[\"diff_word_cnt\"] = train[\"a_word_cnt\"] - train[\"b_word_cnt\"]\ntrain[\"diff_sent_cnt\"] = train[\"a_sent_cnt\"] - train[\"b_sent_cnt\"]\n\n# -----------------------------------------------------------------#\n\na_style = train[\"response_a\"].astype(str).apply(style_counts).apply(pd.Series)\nb_style = train[\"response_b\"].astype(str).apply(style_counts).apply(pd.Series)\na_style.columns = [\"a_exclam\", \"a_qmark\", \"a_commas\"]\nb_style.columns = [\"b_exclam\", \"b_qmark\", \"b_commas\"]\ntrain = pd.concat([train, a_style, b_style], axis=1)\n\nfor col in [\"exclam\", \"qmark\", \"commas\"]:\n    train[f\"diff_{col}\"] = train[f\"a_{col}\"] - train[f\"b_{col}\"]\n\n# -----------------------------------------------------------------#\n\ntrain[\"a_lexdiv\"] = train[\"response_a\"].astype(str).apply(lexical_diversity)\ntrain[\"b_lexdiv\"] = train[\"response_b\"].astype(str).apply(lexical_diversity)\ntrain[\"diff_lexdiv\"] = train[\"a_lexdiv\"] - train[\"b_lexdiv\"]\n\n# -----------------------------------------------------------------#\n\nsia = joblib.load(\"/kaggle/input/vader-model/vader_model.pkl\")\n\ntrain[\"a_sentiment\"] = train[\"response_a\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\ntrain[\"b_sentiment\"] = train[\"response_b\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\ntrain[\"diff_sentiment\"] = train[\"a_sentiment\"] - train[\"b_sentiment\"]\n\n# -----------------------------------------------------------------#\n\ndef outcome_rates(df, feature, bins=10):\n    df = df.copy()\n    df[\"bin\"] = pd.qcut(df[feature], q=bins, duplicates=\"drop\")\n    grouped = (\n    df.groupby(\"bin\", observed=True)[\"win_label\"]\n      .value_counts(normalize=True)\n      .unstack()\n      .fillna(0)\n    )\n    grouped.columns = [\"A_win\", \"B_win\", \"Tie\"]\n    grouped[\"bin_mid\"] = grouped.index.map(lambda b: (b.left + b.right)/2 if hasattr(b, \"left\") else np.nan)\n    return grouped.reset_index()\n\nverbosity_feats = [\"diff_char_len\",\"diff_word_cnt\",\"diff_sent_cnt\"]\nstyle_feats = [\"diff_exclam\", \"diff_qmark\", \"diff_commas\", \"diff_sentiment\", \"diff_lexdiv\"]\n\nsns.set(style=\"whitegrid\")\ntotal_plots = len(verbosity_feats) + len(style_feats)\ncols = (total_plots + 1) // 2\n\nplt.figure(figsize=(15,8))\n\nfor i, f in enumerate(verbosity_feats, 1):\n    plt.subplot(2, cols, i)\n    wr = outcome_rates(train, f)\n    plt.plot(wr[\"bin_mid\"], wr[\"A_win\"], color=\"#4A90E2\", label=\"A win\")\n    plt.plot(wr[\"bin_mid\"], wr[\"B_win\"], color=\"#E94E77\", label=\"B win\")\n    plt.plot(wr[\"bin_mid\"], wr[\"Tie\"],   color=\"#F5C518\", label=\"Tie\")\n    plt.title(f\"Verbosity: {f}\")\n    plt.xlabel(f); plt.ylabel(\"Proportion\"); plt.legend()\n\nfor j, f in enumerate(style_feats, 1):\n    idx = len(verbosity_feats) + j\n    plt.subplot(2, cols, idx)\n    wr = outcome_rates(train, f)\n    plt.plot(wr[\"bin_mid\"], wr[\"A_win\"], color=\"#4A90E2\", label=\"A win\")\n    plt.plot(wr[\"bin_mid\"], wr[\"B_win\"], color=\"#E94E77\", label=\"B win\")\n    plt.plot(wr[\"bin_mid\"], wr[\"Tie\"],   color=\"#F5C518\", label=\"Tie\")\n    plt.title(f\"Style: {f}\")\n    plt.xlabel(f); plt.ylabel(\"Proportion\"); plt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# -----------------------------------------------------------------#\n\ntrain[\"A_win\"] = (train[\"win_label\"] == 0).astype(int)\ntrain[\"B_win\"] = (train[\"win_label\"] == 1).astype(int)\ntrain[\"Tie\"]   = (train[\"win_label\"] == 2).astype(int)\n\ncorr_df = {}\nfor col in [\"A_win\",\"B_win\",\"Tie\"]:\n    corr_df[col] = train[verbosity_feats + style_feats + [col]].corr()[col]\n\ncorr_df = pd.DataFrame(corr_df)\nprint(\"\\n Correlation of features with each outcome:\")\nprint(corr_df.sort_index())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}